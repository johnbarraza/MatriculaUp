{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cb100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\n",
      "  Using cached pillow-12.0.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-5.2.0-py3-none-win_amd64.whl.metadata (67 kB)\n",
      "Collecting charset-normalizer>=2.0.0 (from pdfminer.six==20251107->pdfplumber)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20251107->pdfplumber)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Using cached numpy-2.3.5-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\johnb\\miniconda3\\envs\\up\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber)\n",
      "  Using cached cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\johnb\\miniconda3\\envs\\up\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.6/5.6 MB 49.2 MB/s  0:00:00\n",
      "Using cached pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.5/3.5 MB 34.6 MB/s  0:00:00\n",
      "Using cached cffi-2.0.0-cp311-cp311-win_amd64.whl (182 kB)\n",
      "Using cached numpy-2.3.5-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "Using cached pillow-12.0.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "Downloading pypdfium2-5.2.0-py3-none-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.1/3.1 MB 14.0 MB/s  0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: pytz, tzdata, pypdfium2, pycparser, Pillow, numpy, et-xmlfile, charset-normalizer, pandas, openpyxl, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "\n",
      "   ----------------------------------------  0/14 [pytz]\n",
      "   ----------------------------------------  0/14 [pytz]\n",
      "   -- -------------------------------------  1/14 [tzdata]\n",
      "   -- -------------------------------------  1/14 [tzdata]\n",
      "   -- -------------------------------------  1/14 [tzdata]\n",
      "   ----- ----------------------------------  2/14 [pypdfium2]\n",
      "   ----- ----------------------------------  2/14 [pypdfium2]\n",
      "   -------- -------------------------------  3/14 [pycparser]\n",
      "   ----------- ----------------------------  4/14 [Pillow]\n",
      "   ----------- ----------------------------  4/14 [Pillow]\n",
      "   ----------- ----------------------------  4/14 [Pillow]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   ----------------- ----------------------  6/14 [et-xmlfile]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ---------------------- -----------------  8/14 [pandas]\n",
      "   ------------------------- --------------  9/14 [openpyxl]\n",
      "   ------------------------- --------------  9/14 [openpyxl]\n",
      "   ------------------------- --------------  9/14 [openpyxl]\n",
      "   ------------------------- --------------  9/14 [openpyxl]\n",
      "   ------------------------- --------------  9/14 [openpyxl]\n",
      "   ------------------------- --------------  9/14 [openpyxl]\n",
      "   ------------------------------- -------- 11/14 [cryptography]\n",
      "   ------------------------------- -------- 11/14 [cryptography]\n",
      "   ---------------------------------- ----- 12/14 [pdfminer.six]\n",
      "   ---------------------------------- ----- 12/14 [pdfminer.six]\n",
      "   ------------------------------------- -- 13/14 [pdfplumber]\n",
      "   ---------------------------------------- 14/14 [pdfplumber]\n",
      "\n",
      "Successfully installed Pillow-12.0.0 cffi-2.0.0 charset-normalizer-3.4.4 cryptography-46.0.3 et-xmlfile-2.0.0 numpy-2.3.5 openpyxl-3.1.5 pandas-2.3.3 pdfminer.six-20251107 pdfplumber-0.11.8 pycparser-2.23 pypdfium2-5.2.0 pytz-2025.2 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pdfplumber pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfcf78f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando (v6): C:\\Users\\johnb\\Documents\\Github\\MatriculaUp\\pdfs\\REGULAR_Oferta-Academica-2025-II_18.08_10.03am.pdf\n",
      "¡Listo! Se corrigió el corte de nombres múltiples y las observaciones.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def procesar_horarios_v6_multi_docente(ruta_pdf):\n",
    "    if not os.path.exists(ruta_pdf):\n",
    "        print(f\"Error: No encuentro el archivo: {ruta_pdf}\")\n",
    "        return None\n",
    "\n",
    "    data_procesada = []\n",
    "    \n",
    "    # Contexto\n",
    "    ctx = {\n",
    "        \"codigo\": None, \"curso\": None, \"creditos\": None, \n",
    "        \"prerequisitos\": [], \"observaciones\": None, \n",
    "        \"seccion\": None, \"docente\": None\n",
    "    }\n",
    "    \n",
    "    leyendo_prerequisitos = False\n",
    "    palabras_clave = [\"CLASE\", \"FINAL\", \"PARCIAL\", \"PRÁCTICA\", \"LABORATORIO\", \"EXAMEN\", \"RECUPERACIÓN\"]\n",
    "\n",
    "    print(f\"Procesando (v6): {ruta_pdf}\")\n",
    "    \n",
    "    with pdfplumber.open(ruta_pdf) as pdf:\n",
    "        total_paginas = len(pdf.pages)\n",
    "        \n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            print(f\"Pagina {i + 1}/{total_paginas}...\", end=\"\\r\")\n",
    "            \n",
    "            table = page.extract_table()\n",
    "            if not table: continue\n",
    "                \n",
    "            for row in table:\n",
    "                row = [str(cell).strip() if cell else \"\" for cell in row]\n",
    "                row_str = \" \".join(row)\n",
    "                col0 = row[0]\n",
    "                \n",
    "                if \"Dirección de Asuntos\" in row_str or \"Horarios ofertados\" in row_str: continue\n",
    "                if \"Secc\" in col0 and \"Docentes\" in row_str: continue\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # 1. DETECCIÓN DE CURSO (Igual que antes)\n",
    "                # ---------------------------------------------------------\n",
    "                match_curso = re.search(r'(?<!PREREQUISITO: )(^|\\s)([A-Z0-9]{6})\\s?-\\s?(.*)', row_str)\n",
    "                es_inicio_curso = re.match(r'^[A-Z0-9]{6}\\s?-', col0)\n",
    "                \n",
    "                if match_curso and es_inicio_curso:\n",
    "                    raw_code = match_curso.group(2)\n",
    "                    raw_name = match_curso.group(3).strip()\n",
    "                    \n",
    "                    # Limpieza Créditos\n",
    "                    match_cred = re.search(r'(\\d{1,2},\\d{2})', raw_name)\n",
    "                    if match_cred:\n",
    "                        ctx[\"creditos\"] = match_cred.group(1)\n",
    "                        raw_name = raw_name.replace(match_cred.group(1), \"\")\n",
    "                    \n",
    "                    # Limpieza Prerrequisito Inline\n",
    "                    prereq_inline = \"\"\n",
    "                    if \"PREREQUISITO\" in raw_name:\n",
    "                        parts = raw_name.split(\"PREREQUISITO\")\n",
    "                        raw_name = parts[0]\n",
    "                        prereq_inline = \"PREREQUISITO\" + parts[1]\n",
    "                    \n",
    "                    ctx[\"codigo\"] = raw_code\n",
    "                    ctx[\"curso\"] = raw_name.strip(\" :,-\")\n",
    "                    ctx[\"prerequisitos\"] = [prereq_inline] if prereq_inline else []\n",
    "                    ctx[\"observaciones\"] = None; ctx[\"seccion\"] = None; ctx[\"docente\"] = None\n",
    "                    leyendo_prerequisitos = True\n",
    "                    continue\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # 2. METADATA (Prerrequisitos)\n",
    "                # ---------------------------------------------------------\n",
    "                if leyendo_prerequisitos:\n",
    "                    # Chequeo de fin de metada (Si empieza sección o clase)\n",
    "                    es_seccion = (len(col0) > 0 and len(col0) <= 3 and col0 not in palabras_clave and not re.search(r'\\d', col0))\n",
    "                    es_clase = any(kw in row for kw in palabras_clave)\n",
    "                    \n",
    "                    if es_seccion or es_clase:\n",
    "                        leyendo_prerequisitos = False\n",
    "                    else:\n",
    "                        match_cred = re.search(r'(\\d{1,2},\\d{2})', row_str)\n",
    "                        if match_cred and not ctx[\"creditos\"]:\n",
    "                            ctx[\"creditos\"] = match_cred.group(1)\n",
    "                            row_str = row_str.replace(match_cred.group(1), \"\")\n",
    "\n",
    "                        if text_has_content(row_str):\n",
    "                             ctx[\"prerequisitos\"].append(row_str)\n",
    "                        continue\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # 3. DETECCIÓN DE SECCIÓN Y DOCENTES (LÓGICA MEJORADA)\n",
    "                # ---------------------------------------------------------\n",
    "                es_seccion = (len(col0) > 0 and len(col0) <= 3 and \n",
    "                              col0 not in palabras_clave and not re.search(r'\\d', col0))\n",
    "                \n",
    "                if es_seccion:\n",
    "                    ctx[\"seccion\"] = col0\n",
    "                    \n",
    "                    # A. Construir el bloque de texto sucio (hasta donde empiece el horario)\n",
    "                    texto_sucio_partes = []\n",
    "                    for cell in row[1:]:\n",
    "                        if cell in palabras_clave or re.match(r'\\d{2}:\\d{2}', cell): break\n",
    "                        if cell: texto_sucio_partes.append(cell)\n",
    "                    full_text = \" \".join(texto_sucio_partes)\n",
    "                    \n",
    "                    # B. EXTRAER MÚLTIPLES DOCENTES\n",
    "                    # Regex Mejorada: Acepta Mayúsculas o TitleCase, evita dígitos (fechas)\n",
    "                    # Patrón: Palabras (sin numeros) + Coma + Espacio + Palabras (sin numeros)\n",
    "                    regex_nombre = r'([A-ZÑÁÉÍÓÚ][A-Za-zÑÁÉÍÓÚñáéíóú\\s\\-\\.]+,[\\s]+[A-ZÑÁÉÍÓÚ][A-Za-zÑÁÉÍÓÚñáéíóú\\s\\-\\.]+)'\n",
    "                    \n",
    "                    # Usamos finditer para encontrar TODOS los nombres\n",
    "                    docentes_encontrados = []\n",
    "                    matches = list(re.finditer(regex_nombre, full_text))\n",
    "                    \n",
    "                    for m in matches:\n",
    "                        docente_limpio = m.group(1).strip()\n",
    "                        # Verificación extra: que no sea una fecha disfrazada (aunque el regex evita numeros)\n",
    "                        if len(docente_limpio) > 5:\n",
    "                            docentes_encontrados.append(docente_limpio)\n",
    "                    \n",
    "                    # C. SEPARAR OBSERVACIONES\n",
    "                    # Quitamos los nombres del texto original para ver qué sobra\n",
    "                    obs_sucia = full_text\n",
    "                    for doc in docentes_encontrados:\n",
    "                        obs_sucia = obs_sucia.replace(doc, \"\")\n",
    "                    \n",
    "                    # Limpiamos la basura que queda (slash, comas sueltas, espacios)\n",
    "                    obs_limpia = re.sub(r'^\\s*[/\\-,]\\s*', '', obs_sucia) # Quitar separadores al inicio\n",
    "                    obs_limpia = re.sub(r'\\s*[/\\-,]\\s*$', '', obs_limpia) # Quitar separadores al final\n",
    "                    obs_limpia = re.sub(r'\\s{2,}', ' ', obs_limpia).strip()\n",
    "                    \n",
    "                    # Guardar en Contexto\n",
    "                    if docentes_encontrados:\n",
    "                        ctx[\"docente\"] = \" / \".join(docentes_encontrados)\n",
    "                    else:\n",
    "                        # Si no hay patrón de nombre pero hay texto, todo es observación (o docente mal formateado)\n",
    "                        # Asumiremos observación si dice \"Dictado\", sino docente raw\n",
    "                        if \"Dictado\" in full_text or \"Clases\" in full_text:\n",
    "                            obs_limpia = full_text\n",
    "                        else:\n",
    "                            ctx[\"docente\"] = full_text # Fallback\n",
    "                            \n",
    "                    if len(obs_limpia) > 2:\n",
    "                        ctx[\"observaciones\"] = obs_limpia\n",
    "                    else:\n",
    "                        ctx[\"observaciones\"] = None\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # 4. HORARIOS (Igual que antes)\n",
    "                # ---------------------------------------------------------\n",
    "                tipo_actividad = None\n",
    "                idx_tipo = -1\n",
    "                \n",
    "                for idx, cell in enumerate(row):\n",
    "                    if cell in palabras_clave:\n",
    "                        tipo_actividad = cell; idx_tipo = idx; break\n",
    "                    elif any(kw in cell for kw in palabras_clave) and len(cell) > 5:\n",
    "                        for kw in palabras_clave:\n",
    "                            if kw in cell: tipo_actividad = kw; break\n",
    "                \n",
    "                if tipo_actividad and idx_tipo != -1:\n",
    "                    datos = [x for x in row[idx_tipo+1:] if x != \"\"]\n",
    "                    if len(datos) >= 2:\n",
    "                        prereq_final = \" \".join(ctx[\"prerequisitos\"]).replace(\"PREREQUISITO:\", \"\").strip(\" ()\")\n",
    "                        \n",
    "                        data_procesada.append({\n",
    "                            \"Codigo\": ctx[\"codigo\"],\n",
    "                            \"Curso\": ctx[\"curso\"],\n",
    "                            \"Creditos\": ctx[\"creditos\"],\n",
    "                            \"Seccion\": ctx[\"seccion\"],\n",
    "                            \"Docente\": ctx[\"docente\"],\n",
    "                            \"Observaciones\": ctx[\"observaciones\"],\n",
    "                            \"Tipo\": tipo_actividad,\n",
    "                            \"Dia\": datos[0],\n",
    "                            \"Inicio\": datos[1],\n",
    "                            \"Fin\": datos[2] if len(datos) > 2 else \"\",\n",
    "                            \"Aula\": datos[-1] if len(datos) > 3 else \"\",\n",
    "                            \"Prerrequisitos\": prereq_final\n",
    "                        })\n",
    "\n",
    "    return pd.DataFrame(data_procesada)\n",
    "\n",
    "def text_has_content(text):\n",
    "    return len(text.replace(\",\", \"\").strip()) > 3\n",
    "\n",
    "# Ejecución\n",
    "# ruta_archivo = r\"pdfs\\Oferta-Academica-extraord_CE-2026-12.12.pdf\"\n",
    "ruta_archivo = r\"C:\\Users\\johnb\\Documents\\Github\\MatriculaUp\\pdfs\\REGULAR_Oferta-Academica-2025-II_18.08_10.03am.pdf\"\n",
    "df_final = procesar_horarios_v6_multi_docente(ruta_archivo)\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    df_final.to_excel(\"Horarios_UP_V6_Perfecto.xlsx\", index=False)\n",
    "    print(\"¡Listo! Se corrigió el corte de nombres múltiples y las observaciones.\")\n",
    "else:\n",
    "    print(\"Error: No data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
